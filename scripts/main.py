import argparse
import os
import shutil
import sys
from typing import Dict, List, Tuple

from config import config
from doc_gen import DocGenerator
from monitor import GitHubMonitor


class MainController:
    def __init__(self):
        self.monitor = GitHubMonitor()
        self.doc_gen = DocGenerator()
        self.updated_files = set()
        self.ai_changes = []
        self.docs_root = config.DOCS_ROOT
        self.bootstrap_mode = False

    def _select_bootstrap_files(self, tree_paths: List[str], max_files: int = 12) -> List[str]:
        """ä»ä»“åº“æ–‡ä»¶æ ‘ä¸­æŒ‘é€‰å°‘é‡â€œé«˜ä¿¡å·â€æ–‡ä»¶ï¼Œä¾› bootstrap ç”Ÿæˆæ›´å…·ä½“çš„æ–‡æ¡£ä¸Šä¸‹æ–‡ã€‚"""
        paths = [p.strip().lstrip("./") for p in (tree_paths or []) if p and p.strip()]
        path_set = set(paths)

        # Prefer small, informative, human-written or schema-like files.
        priority_exact = [
            "README.md",
            "README.zh.md",
            "pyproject.toml",
            "requirements.txt",
            "Dockerfile",
            "docker-compose.yml",
            "compose.yml",
            "compose.yaml",
            "template/bot_config_template.toml",
            "template/model_config_template.toml",
        ]

        def is_text_like(p: str) -> bool:
            if p in {"Dockerfile", "Makefile"}:
                return True
            suffixes = (".py", ".md", ".toml", ".yml", ".yaml", ".json", ".ini", ".cfg", ".txt", ".sh", ".env")
            return p.endswith(suffixes)

        selected: List[str] = []
        for p in priority_exact:
            if p in path_set and is_text_like(p):
                selected.append(p)
                if len(selected) >= max_files:
                    return selected

        def add_first_match(pred) -> None:
            for p in paths:
                if p in selected:
                    continue
                if not is_text_like(p):
                    continue
                if pred(p):
                    selected.append(p)
                    return

        # Architecture / core loop hints
        add_first_match(lambda p: "/chat/brain_chat/PFC/" in p and p.endswith("pfc.py"))
        add_first_match(lambda p: "/chat/brain_chat/PFC/" in p and p.endswith("action_planner.py"))

        # Learning system hints
        add_first_match(lambda p: "/bw_learner/" in p and p.endswith("expression_learner.py"))
        add_first_match(lambda p: "/bw_learner/" in p and p.endswith("jargon_miner.py"))

        # Plugin/adapters hints
        add_first_match(lambda p: "/plugins/" in p and p.endswith("_manifest.json"))
        add_first_match(lambda p: "/plugins/" in p and p.endswith("plugin.py"))
        add_first_match(lambda p: "/adapter" in p.lower() and p.endswith(".py"))

        # If still not enough, pick a few representative src python files.
        for p in paths:
            if len(selected) >= max_files:
                break
            if p in selected:
                continue
            if not is_text_like(p):
                continue
            if p.startswith("src/") and p.endswith(".py"):
                selected.append(p)

        return selected[:max_files]

    def _build_repo_context(self, *, head_sha: str, tree_paths: List[str], readme: str) -> str:
        # Keep the prompt small and verifiable: tree summary + a limited README snippet.
        max_readme_chars = 8000
        readme_text = (readme or "").strip()
        if len(readme_text) > max_readme_chars:
            readme_text = readme_text[:max_readme_chars] + "\n\n...[truncated]..."

        # Summarize tree by top-level entries, plus representative paths.
        top_level: Dict[str, List[str]] = {}
        for p in tree_paths:
            top = (p.split("/", 1)[0] or "").strip()
            top_level.setdefault(top, []).append(p)

        lines: List[str] = []
        lines.append(f"Repo: {config.REPO_NAME}")
        lines.append(f"Branch: {config.UPSTREAM_BRANCH}")
        if head_sha:
            lines.append(f"Head: {head_sha}")
        lines.append("")
        lines.append("Top-level entries (file count):")
        for k in sorted(top_level.keys()):
            lines.append(f"- {k}: {len(top_level[k])}")
        lines.append("")
        lines.append("Representative paths:")
        total = 0
        for k in sorted(top_level.keys()):
            examples = sorted(top_level[k])[:20]
            for ex in examples:
                lines.append(f"- {ex}")
                total += 1
                if total >= 300:
                    break
            if total >= 300:
                break

        selected_files = self._select_bootstrap_files(tree_paths, max_files=12)
        file_snippets: List[Tuple[str, str]] = []
        for p in selected_files:
            if p.lower().startswith("readme"):
                continue
            text = self.monitor.get_file_text(p, max_chars=6000)
            if not text.strip():
                continue
            file_snippets.append((p, text))

        if file_snippets:
            lines.append("")
            lines.append("Selected file snippets (truncated):")
            for p, text in file_snippets:
                lines.append(f"--- File: {p} ---")
                lines.append("```text")
                lines.append(text)
                lines.append("```")
        lines.append("")
        lines.append("README (snippet):")
        lines.append(readme_text or "(no README found)")
        lines.append("")
        return "\n".join(lines)

    def _write_snapshot_indexes(self) -> None:
        snapshots_root = os.path.join(self.docs_root, "snapshots")
        if not os.path.isdir(snapshots_root):
            return

        docs_route_prefix = "/" + self.docs_root.strip("/").replace(os.sep, "/")

        versions = sorted(
            [d for d in os.listdir(snapshots_root) if os.path.isdir(os.path.join(snapshots_root, d))],
            reverse=True,
        )

        index_lines = [
            "# æ–‡æ¡£å¿«ç…§",
            "",
            f"è¿™é‡Œå­˜æ”¾æŒ‰ `{config.REPO_NAME}` çš„ Tag å½’æ¡£çš„æ–‡æ¡£å¿«ç…§ï¼ˆä»… `{self.docs_root}`ï¼‰ã€‚",
            "",
        ]
        for v in versions:
            index_lines.append(f"- [{v}]({docs_route_prefix}/snapshots/{v}/)")
        index_lines.append("")

        index_path = os.path.join(snapshots_root, "index.md")
        os.makedirs(os.path.dirname(index_path), exist_ok=True)
        with open(index_path, "w", encoding="utf-8") as f:
            f.write("\n".join(index_lines))
        self.updated_files.add(index_path)

    def handle_release(self, update: Dict) -> None:
        tag_name = update.get("tag_name")
        if not tag_name:
            return

        if not config.ENABLE_SNAPSHOTS:
            return

        snapshot_path = os.path.join(self.docs_root, "snapshots", tag_name)
        docs_path = self.docs_root

        print(f"ğŸš€ æ£€æµ‹åˆ°æ–°ç‰ˆæœ¬å‘å¸ƒï¼š{tag_name}ã€‚æ­£åœ¨åˆ›å»ºæ–‡æ¡£å¿«ç…§...")

        if not os.path.exists(docs_path):
            print(f"âš ï¸ è­¦å‘Šï¼š{docs_path} ä¸å­˜åœ¨ã€‚è·³è¿‡å¿«ç…§åˆ›å»ºã€‚")
            return

        os.makedirs(os.path.join(self.docs_root, "snapshots"), exist_ok=True)
        if os.path.exists(snapshot_path):
            print(f"âš ï¸ è­¦å‘Šï¼šå¿«ç…§ç›®å½• {snapshot_path} å·²å­˜åœ¨ã€‚å°†æ‰§è¡Œè¦†ç›–ã€‚")
            shutil.rmtree(snapshot_path)

        os.makedirs(snapshot_path, exist_ok=True)

        try:
            for item in os.listdir(docs_path):
                if item == "snapshots":
                    continue
                src_item = os.path.join(docs_path, item)
                dst_item = os.path.join(snapshot_path, item)
                if os.path.isdir(src_item):
                    shutil.copytree(src_item, dst_item)
                else:
                    shutil.copy2(src_item, dst_item)

            print(f"âœ… å¿«ç…§å·²åˆ›å»ºè‡³ {snapshot_path}")

            for root, _, files in os.walk(snapshot_path):
                for file in files:
                    self.updated_files.add(os.path.join(root, file))

            self._write_snapshot_indexes()
        except Exception as e:
            print(f"âŒ åˆ›å»ºå¿«ç…§æ—¶å‡ºé”™ï¼š{e}")

    def handle_commit(self, update: Dict, force: bool = False) -> None:
        sha = update.get("sha", "unknown")
        message = update.get("message", "")
        diff = update.get("diff", "")

        print(f"ğŸ“ æ­£åœ¨åˆ†ææäº¤ {sha[:7]}...")
        try:
            if force or self.doc_gen.should_update_docs(message, diff):
                print(f"âœ¨ AI å†³å®šä¸ºæäº¤ {sha[:7]} æ›´æ–°æ–‡æ¡£ã€‚")
                result = self.doc_gen.generate_doc_update(message, diff)
                if result:
                    file_path = result["file_path"]
                    self.updated_files.add(file_path)
                    self.ai_changes.append(result)
            else:
                print(f"â„¹ï¸ AI å†³å®šæ— éœ€ä¸ºæäº¤ {sha[:7]} æ›´æ–°æ–‡æ¡£ã€‚")
        except Exception as e:
            print(f"âŒ å¤„ç†æäº¤ {sha[:7]} æ—¶å‡ºé”™ï¼š{e}")

    def run(self, force_latest: bool = False) -> None:
        print("=== LLM æ–‡æ¡£è‡ªåŠ¨åŒ–åŒæ­¥å¼€å§‹ ===")
        try:
            if self.bootstrap_mode:
                head_sha = self.monitor.get_head_sha()
                readme = self.monitor.get_readme_text()
                tree_paths = self.monitor.get_repo_tree_paths()

                latest_tag = self.monitor.get_latest_tag_name() if config.ENABLE_SNAPSHOTS else ""
                self.monitor.save_state({"last_commit_sha": head_sha, "last_tag": latest_tag})

                repo_context = self._build_repo_context(head_sha=head_sha, tree_paths=tree_paths, readme=readme)
                created = self.doc_gen.generate_bootstrap_docs(repo_context)
                for item in created:
                    file_path = item.get("file_path")
                    if file_path:
                        self.updated_files.add(file_path)
                        self.ai_changes.append(item)

                self.output_summary([{"type": "bootstrap", "sha": head_sha}])
                return

            updates, new_state = self.monitor.check_for_updates(force_latest=force_latest)
            if not updates:
                print("ğŸ æœªå‘ç°æ–°å˜æ›´ã€‚é€€å‡ºã€‚")
                return

            processed_updates: List[Dict] = []
            for update in updates:
                if update.get("type") == "release":
                    self.handle_release(update)
                    processed_updates.append(update)
                elif update.get("type") == "commit":
                    self.handle_commit(update, force=force_latest)
                    processed_updates.append(update)

            self.monitor.save_state(new_state)
            print("ğŸ’¾ çŠ¶æ€è®°å½•å·²æ›´æ–°ã€‚")
            self.output_summary(processed_updates)
        except Exception as e:
            print(f"ğŸ’¥ ä¸»å¾ªç¯å‡ºç°ä¸¥é‡é”™è¯¯ï¼š{e}")
            sys.exit(1)
        print("=== LLM æ–‡æ¡£è‡ªåŠ¨åŒ–åŒæ­¥å®Œæˆ ===")

    def output_summary(self, updates: List[Dict]) -> None:
        if not self.updated_files:
            print("ğŸ“ æ²¡æœ‰æ–‡ä»¶è¢«åˆ›å»ºæˆ–æ›´æ–°ã€‚")
            return

        print("\n" + "=" * 20 + " æ€»ç»“ " + "=" * 20)
        print(f"æ€»è®¡æ›´æ–°æ–‡ä»¶æ•°: {len(self.updated_files)}")
        for f in sorted(self.updated_files):
            print(f"- {f}")

        if os.getenv("GITHUB_ACTIONS") == "true":
            github_output = os.getenv("GITHUB_OUTPUT")
            if github_output:
                latest_update = updates[-1] if updates else {}
                branch = config.UPSTREAM_BRANCH
                repo_slug = (config.REPO_NAME.split("/")[-1] if config.REPO_NAME else "repo").strip() or "repo"

                if latest_update.get("type") == "bootstrap":
                    head_sha = (latest_update.get("sha") or "")[:7]
                    pr_title = f"docs({repo_slug}@{branch}): åˆå§‹åŒ– LLM æ–‡æ¡£åŸºçº¿"
                    pr_body = (
                        f"ğŸ§± åŸºäº `{config.REPO_NAME}`@`{branch}` çš„å½“å‰ä»£ç å¿«ç…§ç”Ÿæˆåˆå§‹ LLM æ–‡æ¡£åˆ†å—ã€‚\n\n"
                        + (f"Head: `{head_sha}`\n\n" if head_sha else "")
                    )
                elif latest_update.get("type") == "release":
                    tag_name = latest_update.get("tag_name")
                    pr_title = f"docs({repo_slug}@{branch}): å½’æ¡£ç‰ˆæœ¬ {tag_name}"
                    pr_body = f"ğŸš€ æ£€æµ‹åˆ° `{config.REPO_NAME}` æ–°ç‰ˆæœ¬å‘å¸ƒï¼š`{tag_name}`ã€‚\n\næœ¬ PR è‡ªåŠ¨åˆ›å»ºäº†è¯¥ç‰ˆæœ¬çš„æ–‡æ¡£å¿«ç…§ï¼ˆä»… LLM è‡ªåŠ¨ç»´æŠ¤éƒ¨åˆ†ï¼‰ã€‚"
                else:
                    sha = (latest_update.get("sha") or "")[:7]
                    pr_title = f"docs({repo_slug}@{branch}): è‡ªåŠ¨åŒæ­¥æäº¤ {sha}"
                    pr_body = f"ğŸ“ åŸºäº `{config.REPO_NAME}`@`{branch}` æäº¤ `{latest_update.get('sha', '')}` è‡ªåŠ¨æ›´æ–°æ–‡æ¡£ã€‚\n\n"

                    if self.ai_changes:
                        pr_body += "### ğŸ¤– AI æ”¹åŠ¨åˆ†æ\n"
                        for change in self.ai_changes:
                            action_str = "åˆ›å»º" if change.get("action") == "create" else "æ›´æ–°"
                            pr_body += f"- **{action_str}** `{change.get('file_path')}`: {change.get('title')}\n"
                        pr_body += "\n"

                with open(github_output, "a", encoding="utf-8") as f:
                    f.write("has_updates=true\n")
                    f.write(f"files_count={len(self.updated_files)}\n")
                    f.write(f"pr_title={pr_title}\n")
                    f.write("pr_body<<EOF\n")
                    f.write(f"{pr_body}\n")
                    f.write("\n**æ›´æ–°æ–‡ä»¶åˆ—è¡¨**ï¼š\n")
                    for file in sorted(self.updated_files):
                        f.write(f"- {file}\n")
                    f.write("EOF\n")

            print("[GHA] has_updates=true")


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="MaiBot Docs Automation")
    parser.add_argument("--force-latest", action="store_true", help="Force sync with the latest commit")
    parser.add_argument("--bootstrap", action="store_true", help="Generate initial docs baseline from repo snapshot")
    args = parser.parse_args()

    controller = MainController()
    controller.bootstrap_mode = bool(args.bootstrap)
    controller.run(force_latest=args.force_latest)
