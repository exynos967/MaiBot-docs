---\ntitle: LLM 客户端适配与重试机制\nlast_updated: 2026-01-19\n---\n\n## 概述\n本规范详细说明了系统中大语言模型（LLM）调用的核心基础设施，主要涉及多模型供应商（OpenAI, Gemini）的适配、请求编排逻辑、负载均衡以及自动化的故障切换（Failover）与重试机制。\n\n## 目录/结构\n- **src/llm_models**: 提供 LLM 调用的核心基础设施，包括请求编排器 `LLMRequest`、Token 消耗持久化记录 `LLMUsageRecorder`、以及定义了 `ModelAttemptFailed` 等异常的 `exceptions.py`。\n- **src/llm_models/model_client**: 模型客户端适配层，通过 `BaseClient` 定义统一接口，包含 `OpenaiClient` 和 `GeminiClient` 具体实现，并使用 `ClientRegistry` 进行动态扩展。\n\n## 适用范围\n- **请求编排**: 由 `LLMRequest` 负责模型选择、多模态处理（如图片/音频）及重试策略。\n- **客户端管理**: 由 `ClientRegistry` 负责不同 `APIProvider` 类型的客户端类注册与单例缓存。\n- **状态处理**: 支持文本响应、嵌入向量生成及音频转录等多种请求类型 (`RequestType`)。\n\n## 变更影响分析\n- **故障切换机制**: `LLMRequest._execute_request` 实现了跨模型的故障切换逻辑。当单个模型所有重试均失败并抛出 `ModelAttemptFailed` 时，调度器将切换至下一个可用模型。\n- **Token 与耗时记录**: `LLMUsageRecorder` 负责将 LLM 调用的消耗、耗时和成本信息异步记录到 `LLMUsage` 数据库表中。\n- **图片压缩优化**: `compress_messages` 工具函数会对消息中的图片进行压缩（如 JPEG 转换），以优化 Token 成本和传输效率。\n\n## 证据\n- `class LLMRequest`: 主要的LLM请求编排类，处理模型选择、重试、多模态输入（图片/音频）及嵌入生成。\n- `class ClientRegistry`: 负责管理不同 APIProvider 类型的客户端类注册与单例缓存。\n- `LLMUsageRecorder`: 用于将LLM Token消耗、耗时和成本信息异步记录到数据库中。\n- `class OpenAIClient`: 适配 OpenAI 协议，支持标准的流式处理及推理内容提取。